import math
import struct
import numpy as np
import csv,pprint
import random
import matplotlib.pyplot as plt
from matplotlib import cbook
from matplotlib import cm
from matplotlib.colors import LightSource


import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data
import torch.nn.functional as F

import torchsummary


from torchvision.datasets import mnist
from torchvision import datasets,transforms

def float_to_hex(f):
    return hex(struct.unpack('<I', struct.pack('<f', f))[0])[2:]
def hex_to_float(h):
    return struct.unpack('<f', struct.pack('<I', h))[0]
def to_binary(num,width=16):
    s=''
    for i in range(width):
        s=('%d'%(num%2))+s
        num=num//2
    return ('%d\'b'%width)+s




class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 20)
        self.fc2 = nn.Linear(20, 10)
    
    def forward(self, x):
        x = x.view(-1, 784)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


input2=[[[-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.783302068710327, 1.2304575443267822, 0.22492696344852448, -0.4242129623889923, -0.4242129623889923, -0.029637714847922325, -0.2969306409358978, 0.09764464199542999, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.757845640182495, 2.757845640182495, 2.757845640182495, 0.8867951035499573, 0.8740668296813965, 2.0068798065185547, 1.2304575443267822, 2.4014549255371094, 0.8740668296813965, 0.08491640537977219, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 0.8486104011535645, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 0.8486104011535645, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.09764464199542999, 2.14689040184021, 2.14689040184021, 2.14689040184021, 2.2996292114257812, 2.783302068710327, 2.783302068710327, 2.783302068710327, 2.808758497238159, 2.783302068710327, 0.8486104011535645, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.2842023968696594, -0.029637714847922325, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.029637714847922325, 1.4722939729690552, 1.4722939729690552, 2.5160090923309326, 2.783302068710327, 2.757845640182495, 0.8486104011535645, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.029637714847922325, 1.2304575443267822, 0.08491640537977219, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 2.14689040184021, 2.783302068710327, 2.757845640182495, 0.8486104011535645, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.029637714847922325, 1.2304575443267822, 0.08491640537977219, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.6195022463798523, 2.14689040184021, 2.643291473388672, 2.783302068710327, 2.757845640182495, 0.8486104011535645, -0.4242129623889923, -0.4242129623889923, 0.6195022463798523, 2.14689040184021, 0.08491640537977219, 0.22492696344852448, 1.4722939729690552, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.8740668296813965, 2.783302068710327, 2.783302068710327, 2.159618616104126, -0.4242129623889923, -0.029637714847922325, 0.22492696344852448, 0.7467845678329468, 2.783302068710327, 2.783302068710327, 2.783302068710327, 2.68147611618042, 1.1159032583236694, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.8740668296813965, 2.757845640182495, 2.757845640182495, 2.4014549255371094, 0.8740668296813965, 2.0068798065185547, 2.757845640182495, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 1.1159032583236694, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.08491640537977219, 1.9941515922546387, 2.757845640182495, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 1.5995763540267944, 0.8486104011535645, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.6195022463798523, 2.5160090923309326, 2.757845640182495, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 1.7268586158752441, -0.16964827477931976, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.09764464199542999, 0.7467845678329468, 2.783302068710327, 2.783302068710327, 2.783302068710327, 2.808758497238159, 2.783302068710327, 2.783302068710327, 0.19947050511837006, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.09764464199542999, 0.8740668296813965, 2.3887267112731934, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 1.981423258781433, -0.05509417876601219, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.029637714847922325, 2.0068798065185547, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 1.981423258781433, 0.08491640537977219, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.783302068710327, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.274172782897949, -0.05509417876601219, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.783302068710327, 2.783302068710327, 2.783302068710327, 2.821486711502075, 2.783302068710327, 2.783302068710327, 0.19947050511837006, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.757845640182495, 2.757845640182495, 2.757845640182495, 2.5287373065948486, 1.4722939729690552, 1.4722939729690552, -0.05509417876601219, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.757845640182495, 2.757845640182495, 2.757845640182495, 0.5940457582473755, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, 0.22492696344852448, 2.757845640182495, 2.757845640182495, 2.757845640182495, 1.6504892110824585, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923], [-0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923, -0.4242129623889923]]]
input2=[[[-0.4242129623889923 for _ in range(28)] for _ in range(28)]]#-0.4242129623889923
for i in range(15,17):
    for j in range(6,22):
        input2[0][j][i]=2.9
for i in range(10,12):
    for j in range(7,15):
        input2[0][j][i]=2.9
for i in range(10,22):
    for j in range(14,16):
        input2[0][j][i]=2.9
fig, ax = plt.subplots()
im = ax.imshow(np.array(input2)[0]*0.3081+0.1307, cmap='binary')
#c = ax.pcolor(input2, cmap='RdBu', vmin=-1, vmax=1)


# Rotate the tick labels and set their alignment.
plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
         rotation_mode="anchor")

# Loop over data dimensions and create text annotations.

ax.set_title("Reward correlation")
fig.tight_layout()
plt.show()


nn=Net()
nn_state_dict = torch.load("tmp/model_simple 003 not overfit.txt")
nn.load_state_dict(nn_state_dict) 

torchsummary.summary(nn,input_size=(1,28,28))

offset=0
x=0
with open("nn_simple_check.txt", mode='w') as f:
    x=torch.tensor([input2])
    f.write("memory_initialization_radix=16;\nmemory_initialization_vector=\n")
    for i in range(28):
        for j in range(28):
            
            f.write(to_binary(offset)+': '+float_to_hex(input2[0][i][j])+"\n")
            offset+=1
    
    #================================
    tensor=nn.fc1.weight.detach().numpy()
    for i in range(20):
            for j in range(784):
                    f.write(to_binary(offset)+': '+float_to_hex(tensor[i][j])+"\n")
                    offset+=1
                    
    tensor=nn.fc1.bias.detach().numpy()
    for i in range(20):
        f.write(to_binary(offset)+': '+float_to_hex(tensor[i])+"\n")
        offset+=1
    x = x.view(-1, 784)
    x = F.relu(nn.fc1(x))
    offset+=20
    for i in range(20):
        f.write(to_binary(offset)+': '+float_to_hex(x[0][i])+"\n")
        offset+=1
    print(offset,"(16524)")
    #================================
    tensor=nn.fc2.weight.detach().numpy()
    for i in range(10):
            for j in range(20):
                    f.write(to_binary(offset)+': '+float_to_hex(tensor[i][j])+"\n")
                    offset+=1
                    
    tensor=nn.fc2.bias.detach().numpy()
    for i in range(10):
        f.write(to_binary(offset)+': '+float_to_hex(tensor[i])+"\n")
        offset+=1
    offset+=10
    x=nn.fc2(x)
    for i in range(10):
        f.write(to_binary(offset)+': '+float_to_hex(x[0][i])+"\n")
        offset+=1
    print(offset,"(16754)")
        
        
    f.write(";")


def hex_to_float(h):
    return struct.unpack('<f', struct.pack('<I', h))[0]
x=torch.tensor([input2])
x = x.view(-1, 784)
x = nn.fc1(x)
matrix=nn.fc1.weight.detach().numpy()
bias=nn.fc1.bias.detach().numpy()
result_alt=(matrix@(np.array(input2).reshape(784,-1))).reshape(20)+bias

mul=(matrix@(np.array(input2).reshape(784,-1))).reshape(20)

for i in range(20):
    print(float_to_hex(mul[i]))
print("===========================")
for i in range(20):
    print(float_to_hex(result_alt[i]))


x = F.relu(x)
matrix=nn.fc2.weight.detach().numpy()
mul=(matrix@(x.detach().numpy().reshape(20,-1))).reshape(10)
print("===========================")
for i in range(10):
    print(float_to_hex(mul[i]))
bias=nn.fc2.bias.detach().numpy()
result_alt=mul+bias

x=nn.fc2(x)





















 